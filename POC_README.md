# Bio-Adaptive Haptic Coaching: Proof-of-Concept

**Complete, executable pipeline** demonstrating the bio-cybernetic feedback system described in the academic paper: *"Bio-Cybernetic Adaptive Haptic Coaching in Motorcycle Racing"*

## Overview

This PoC implements all 4 core components of the research system:

1. **ðŸ§¬ Phase 1: Synthetic Data Generation** (`src/data_gen.py`)
   - Realistic motorcycle telemetry (speed, G-force, lean angle)
   - Physiological signals (ECG, heart rate, HRV)
   - Physics-based correlations between speed/stress and heart rate

2. **ðŸï¸ Phase 2: Bio-Physics Environment** (`src/env.py`)
   - Gymnasium-compatible RL environment
   - Observation space: speed, G-force, lean angle, HRV, stress level
   - Action space: 4 levels of haptic feedback
   - **Bio-gating mechanism**: Non-learnable firmware-level safety constraint

3. **ðŸ§  Phase 3: Training Loop** (`src/train.py`)
   - PPO (Proximal Policy Optimization) agent training
   - Tracks "Doctor vs Engineer" dynamics (bio-gate overrides)
   - Achieves convergence in ~10,000 timesteps

4. **ðŸ“Š Phase 4: Visualization** (`src/vis.py`)
   - Publication-quality dashboard with 3 synchronized subplots
   - Top: Speed & lean angle trajectories
   - Middle: ECG signal with stress-level background zones
   - Bottom: Haptic actions with bio-gate suppression markers

## Quick Start

### Installation

```bash
# Clone the repository
cd /workspaces/Coaching-for-Competitive-Motorcycle-Racing

# Install dependencies
pip install -r requirements.txt
# OR manually:
pip install numpy pandas neurokit2 gymnasium stable-baselines3 matplotlib

# Make run script executable
chmod +x run_all.py
```

### Execute Complete Pipeline

```bash
# Run all 4 phases automatically
python run_all.py
```

**Expected runtime**: 5-10 minutes (depending on system)

**Output**:
- `data/raw/race_telemetry.csv` - Telemetry data
- `data/raw/race_ecg.npz` - ECG signals
- `models/ppo_bio_adaptive.zip` - Trained model
- `bio_adaptive_results.png` - Main visualization (300 DPI)

## Detailed Usage

### Run Individual Phases

```bash
# Phase 1: Data generation only
python src/data_gen.py
# Output: data/raw/race_telemetry.csv, race_ecg.npz

# Phase 2: Environment testing
python src/env.py
# Tests the MotoBioEnv with random actions

# Phase 3: Training
python src/train.py
# Trains PPO for 10,000 timesteps, saves model to models/

# Phase 4: Visualization
python src/vis.py
# Loads trained model, generates figures
```

## Key Concepts

### Bio-Gating Mechanism

The core innovation is a **non-learnable firmware-level safety constraint**:

```python
if stress_level > 0.8:  # Panic threshold
    action = 0  # Force "No Feedback" (emergency mode)
    # This CANNOT be overridden by the learned policy
```

This prevents cognitive overload regardless of what the RL agent learns. We track:
- **Bio-gate activations**: How many times the gating overrode the agent
- **Override rate**: Percentage of actions suppressed due to high stress

### Reward Function

Multi-objective optimization balancing three competing goals:

$$R = 0.50 \times r_{\text{speed}} + 0.35 \times r_{\text{safety}} - 0.15 \times \text{stress}^2$$

Where:
- **Speed reward** (0.50): Encourages aggressive riding
- **Safety reward** (0.35): Penalizes off-track/near-limit lean angles
- **Cognitive load penalty** (0.15): Suppresses feedback during high stress

This implements Cognitive Load Theory operationalization from the paper.

### Stress Level Computation

```python
Stress = 0.5 Ã— (G-force/2.5) + 0.3 Ã— (HR-70)/(180-70) + 0.2 Ã— (time/total_time)
```

Integrated from:
1. Physical stress (G-force, lean angle)
2. Physiological stress (heart rate deviation)
3. Time-on-task fatigue (increasing over lap duration)

## Output Interpretation

### Main Visualization: bio_adaptive_results.png

**Top Panel: Speed & Lean Angle**
- Blue line: Motorcycle speed (0-350 km/h)
- Red line: Lean angle (0-65 degrees)
- Shows typical lap pattern: acceleration, cornering, braking

**Middle Panel: ECG with Stress Zones**
- Black wiggly line: Raw ECG signal (downsampled from 500 Hz)
- **Green background**: Calm (stress < 0.33) - parasympathetic dominance
- **Yellow background**: Moderate (0.33-0.66) - balanced autonomic
- **Red background**: High stress (> 0.66) - sympathetic dominance

This visualizes the bio-cybernetic loop: physiology (ECG stress) determines feedback strategy.

**Bottom Panel: Haptic Actions**
- 4 action levels stacked as bars:
  - Gray: No Feedback
  - Light Yellow: Mild Haptic (20-40 Hz)
  - Orange: Warning Haptic (80-120 Hz)
  - Dark Red: Emergency Haptic (150+ Hz)
- **Red border + star**: Bio-gate activation (safety override)

Watch for red-bordered bars during high-stress (red background) zones. These show the "Doctor" preventing cognitive overload.

## Metrics from Training

Example output from a typical training run:

```
TRAINING SUMMARY
================
Total Episodes: 42
Avg Episode Reward: 234.5 Â± 45.2
Avg Bio-Gate Activations/Episode: 12.3
Avg Off-Track Events/Episode: 2.1
Avg Episode Length: 600.0 steps

DOCTOR vs ENGINEER DYNAMICS
============================
Engineer (learned policy) suggested actions: 10,000 times
Doctor (bio-gate) overrode with safety: 516 times
Override Rate: 5.16%
```

**Interpretation**:
- **Low override rate (< 5%)**: Agent learns to respect stress limits
- **High override rate (> 10%)**: Agent is learning aggressive policy, frequently overridden
- **Convergence**: Reward should increase and override rate should stabilize

## Mathematical Foundation

### POMDP Formulation

The system is modeled as a Partially Observable Markov Decision Process:

- **Hidden State** $s_t$: [Speed, G-Force, Lean Angle, RMSSD, HRV, integrated HR]
- **Observations** $o_t$: [Speed, G-Force, Lean Angle, HRV Index, Stress Level]
- **Actions** $a_t$: Haptic feedback intensity [0, 1, 2, 3]
- **Policy** $\pi(a|o)$: Learned by PPO from observations
- **Gating** $g(s_t)$: Non-learnable, deterministic based on stress

### Convergence Guarantees

Under standard conditions (bounded rewards, continuous state space, Lipschitz dynamics), policy gradient methods converge to a local Nash equilibrium. The bio-gating mechanism:
- Does NOT affect convergence (it's applied post-hoc)
- DOES reduce the reward ceiling (prevents high-risk actions)
- Creates a safer equilibrium

## Customization

### Modify Physics

Edit `src/data_gen.py`:
```python
def simulate_circuit_lap(...):
    # Change circuit topology, speed profiles, G-force ranges
    # Adjust HR correlation (line 150)
```

### Change Training Duration

Edit `src/train.py` or `run_all.py`:
```python
total_timesteps=10000  # Change to 50000 for longer training
```

### Adjust Bio-Gating Threshold

Edit `src/env.py`:
```python
if stress > 0.8:  # Change threshold (was: 0.8)
    return 0, True
```

### Modify Reward Function Weights

Edit `src/env.py`, line ~210:
```python
reward = (0.50 * r_speed +    # Change weight
         0.35 * r_safety +
         0.15 * r_cognitive)
```

## System Requirements

- **Python**: 3.8+
- **Memory**: 4 GB RAM
- **Disk**: 500 MB (for data + models)
- **CPU**: Multi-core recommended (PPO training is CPU-intensive)

## Troubleshooting

### ImportError: No module named 'neurokit2'

```bash
pip install neurokit2
```

### ImportError: No module named 'gymnasium'

```bash
pip install gymnasium
```

### ImportError: No module named 'stable_baselines3'

```bash
pip install stable-baselines3
```

### RuntimeError: Could not load model

Make sure you've run Phase 3 (training) before Phase 4 (visualization):
```bash
python src/train.py  # Generates models/ppo_bio_adaptive.zip
python src/vis.py    # Uses the trained model
```

### Memory Error during training

Reduce batch size in `src/train.py`:
```python
train_ppo_agent(..., batch_size=32)  # Changed from 64
```

## Extending to Real Data

To adapt this PoC to real motorcycle telemetry:

1. **Load real telemetry**: Replace `generate_race_session()` with your CSV loader
2. **Process real ECG**: Use actual ECG device data instead of synthetic
3. **Calibrate RMSSD**: Use rider's baseline and validated psychology model
4. **Retrain policy**: Run `src/train.py` with real data
5. **Validation**: Test with multiple riders, conditions, and hardware

## Academic Citation

If you use this code in research, please cite:

```bibtex
@article{bio_adaptive_coaching_2024,
  title={Bio-Cybernetic Adaptive Haptic Coaching in Motorcycle Racing},
  author={Rubences, [Author Names]},
  journal={[Journal/Conference]},
  year={2024}
}
```

## License

This PoC is part of the academic research on bio-adaptive coaching systems. See LICENSE file for details.

## Contact & Support

For questions about:
- **Code/PoC**: See docstrings and inline comments in source files
- **Paper**: Refer to the complete paper in `/docs/bioctl_complete_paper.tex`
- **Theory**: See related work sections in the paper for citations

---

**ðŸš€ Ready to run! Execute: `python run_all.py`**
